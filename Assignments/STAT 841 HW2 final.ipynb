{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and Manipulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4858, 363)\n",
      "(944, 363)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as math\n",
    "import random as random\n",
    "from sklearn import linear_model\n",
    "train_faces = loadmat('faces.mat')['train_faces']\n",
    "train_nonfaces = loadmat('faces.mat')['train_nonfaces']\n",
    "test_faces = loadmat('faces.mat')['test_faces']\n",
    "test_nonfaces = loadmat('faces.mat')['test_nonfaces']\n",
    "\n",
    "# Add Y response to training and testing sets\n",
    "N=2429\n",
    "zeros = np.zeros((N,1))\n",
    "ones = np.ones((N,1))\n",
    "train_faces =  np.append(train_faces, ones, 1)\n",
    "train_faces = np.uint8(train_faces)\n",
    "train_nonfaces = np.append(train_nonfaces, zeros, 1)\n",
    "train_nonfaces = np.uint8(train_nonfaces)\n",
    "\n",
    "train_faces[0:2]\n",
    "train_nonfaces[0:3]\n",
    "\n",
    "N=472\n",
    "zeros = np.zeros((N,1))\n",
    "ones = np.ones((N,1))\n",
    "test_faces =  np.append(test_faces, ones, 1)\n",
    "test_faces = np.uint8(test_faces)\n",
    "test_nonfaces = np.append(test_nonfaces, zeros, 1)\n",
    "test_nonfaces = np.uint8(test_nonfaces)\n",
    "\n",
    "# merge train_faces with train_nonfaces, test_faces with test_nonfaces\n",
    "training_data = np.concatenate((train_faces, train_nonfaces), axis=0)\n",
    "training_data = np.insert(training_data, 0, 1, axis=1)\n",
    "\n",
    "testing_data = np.concatenate((test_faces, test_nonfaces), axis=0)\n",
    "testing_data = np.insert(testing_data, 0, 1, axis=1)\n",
    "print(training_data.shape) \n",
    "print(testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1 Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 parameter estimates are [ -1.57669975e+01  -9.86760937e-02  -2.76040412e-02   3.76605690e-02\n",
      "   2.12393352e-04]\n",
      "Training Accuracy is 0.985384932071\n",
      "Training Error is 0.0146150679292\n",
      "Testing Accuracy is 0.51906779661\n",
      "Testing Error is 0.48093220339\n"
     ]
    }
   ],
   "source": [
    "# Implement logistic regression\n",
    "def logistic_func(X,y, num_beta, maxiter):\n",
    "    beta_start = np.zeros((num_beta))\n",
    "    beta = beta_start\n",
    "    i = 0\n",
    "    diff = np.ones((maxiter))\n",
    "    J_bar =np.zeros((num_beta,num_beta))\n",
    "#    l=0\n",
    "    for i in range(maxiter):\n",
    "        beta_old = beta\n",
    "        p = np.exp(np.dot(X, beta))/ (1. + np.exp(np.dot(X, beta)))\n",
    "#        l = np.sum(y*np.log(p) + (1.-y)*np.log(1.-p)) # log-likeliehood\n",
    "        s = np.dot(y-p,X).reshape(362,1)                            # scoring function\n",
    "        J_bar = np.dot(X.T*np.multiply(p,1.-p),X)      # information matrix\n",
    "        beta = beta_old + np.ravel(np.dot(np.linalg.inv(J_bar),s))# new value of beta\n",
    "        diff[i] = np.sum(np.fabs(beta-beta_old)) # sum of absolute differences\n",
    "        i += 1\n",
    "    \n",
    "    return beta, J_bar, diff\n",
    "random.seed(2017)\n",
    "results = logistic_func(X=training_data[:,0:362], y = training_data[:,-1],maxiter =1000,num_beta = 362)\n",
    "print(\"The first 5 parameter estimates are\",results[0][0:5]) # First 5 Beta hats\n",
    "\n",
    "\n",
    "beta = results[0]\n",
    "\n",
    "# training: predicted y\n",
    "y_hat_train = np.round(1 / (1 + np.exp(-np.dot(training_data[:,0:362],beta)))) \n",
    "# Training Accuracy:0.985\n",
    "# Training Error: 0.015\n",
    "print(\"Training Accuracy is\",(y_hat_train == training_data[:,-1]).sum().astype(float) / len(y_hat_train))\n",
    "print(\"Training Error is\", 1 - ((y_hat_train == training_data[:,-1]).sum().astype(float) / len(y_hat_train)))\n",
    "\n",
    "# testing: predicted y\n",
    "y_hat_test = np.round(1 / (1 + np.exp(-np.dot(testing_data[:,0:362],beta)))) \n",
    "# Testing Accuracy: 0.519\n",
    "# Testing Error: 0.481\n",
    "print(\"Testing Accuracy is\",(y_hat_test == testing_data[:,-1]).sum().astype(float) / len(y_hat_test))\n",
    "print(\"Testing Error is\", 1 - ((y_hat_test == testing_data[:,-1]).sum().astype(float) / len(y_hat_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1 Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train)\tmin:  0.0 \tmax:  1.0\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(training_data)\n",
    "X = training_data[:,1:362] / training_data[:,1:362].max(axis=0)\n",
    "print('train)\\tmin: ', np.min(X), '\\tmax: ', np.max(X))\n",
    "\n",
    "#Output\n",
    "y=training_data[:,-1].reshape(4858,1)\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "#Derivative of Sigmoid Function\n",
    "def derivatives_sigmoid(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def NN2(X, y, epoch, lr):\n",
    "    lr = lr\n",
    "    NumInputNeurons = 361\n",
    "    NumHiddenNeurons = 4\n",
    "    NumOutputNeurons = 1\n",
    "      \n",
    "#    wh=np.random.uniform(low=0.0, high=1.0/1000000, size=(NumInputNeurons,NumHiddenNeurons))\n",
    "#    wout=np.random.uniform(low=0.0, high=1.0/1000000,size=(NumHiddenNeurons,NumOutputNeurons))\n",
    "    random.seed(2017)\n",
    "    wh=np.random.uniform(low=-0.5, high=0.5, size=(NumInputNeurons,NumHiddenNeurons))\n",
    "    wout=np.random.uniform(low=-0.5, high=0.5,size=(NumHiddenNeurons,NumOutputNeurons))\n",
    "    for i in range(epoch):\n",
    "        for j in range(4858):\n",
    "            # feedforward for each observation/row in X\n",
    "            a_j = np.dot(X[[j]].reshape(1,361), wh) # a_j[j] is 1 by 4 vector: linear comb output in hidden layer based on X[j]= 4 values\n",
    "            z_j = sigmoid(a_j) # z_j[j] is 1 by 4 vector: sigmoid transformation output in hidden layer based on X[j]\n",
    "            a_k = np.dot(a_j.reshape(1,4), wout) # a_k[j] is 1 by 1 value in output layer\n",
    "            z_k = sigmoid(a_k) # z_k[j] is 1 by 1 value in output layer   \n",
    "               \n",
    "            # backpropagation\n",
    "            wout = np.ravel(wout) + (2 * lr *(y[[j]] - z_k) * (z_k * (1-z_k))) * z_j\n",
    "            wout = wout.reshape(4,1)\n",
    "            \n",
    "            a = ((2 * lr *(y[[j]] - z_k) * (z_k * (1-z_k))) * z_j).T # 4 by 1\n",
    "            b = np.dot(X[[j]].T, (np.ravel(a) * np.ravel(wout) * np.ravel(z_j * (1-z_j))).reshape(1,4))\n",
    "            wh = wh + b\n",
    "    return wh, wout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = NN2(X,y, epoch = 50, lr = 0.01)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 0.930218196789\n",
      "Training Error is 0.0697818032112\n",
      "Testing Accuracy is 0.501059322034\n",
      "Testing Error is 0.498940677966\n"
     ]
    }
   ],
   "source": [
    "# predict on training data\n",
    "random.seed(2017)\n",
    "np.random.shuffle(training_data)\n",
    "X_train = training_data[:,1:362] / training_data[:,1:362].max(axis=0)\n",
    "# print('train)\\tmin: ', np.min(X_train), '\\tmax: ', np.max(X))\n",
    "\n",
    "#Output\n",
    "y_train=training_data[:,-1].reshape(4858,1)\n",
    "      \n",
    "a_j = np.dot(X_train, weight[0]) # a_j is 4858 by 4 vector: linear comb output in hidden layer based on X\n",
    "z_j = sigmoid(a_j) # z_j is 4858 by 4 vector: sigmoid transformation output in hidden layer based on X\n",
    "a_k = np.dot(a_j, weight[1]) # a_k is 4858 by 1 value in output layer\n",
    "z_k = sigmoid(a_k)\n",
    "\n",
    "prediction_training = np.zeros((4858,1))\n",
    "for i in range(4858):\n",
    "    if z_k[[i]] >= 0.50:\n",
    "        prediction_training[[i]] = 1\n",
    "    else:\n",
    "        prediction_training[[i]] = 0\n",
    "\n",
    "print(\"Training Accuracy is\",(np.sum(prediction_training == y_train))/ len(prediction_training)) # training accuracy 0.99\n",
    "print(\"Training Error is\", 1 - ((np.sum(prediction_training == y_train))/ len(prediction_training)))\n",
    "\n",
    "# predict on testing data\n",
    "random.seed(2017)\n",
    "np.random.shuffle(testing_data)\n",
    "X_test = testing_data[:,1:362] / testing_data[:,1:362].max(axis=0)\n",
    "# print('test)\\tmin: ', np.min(X_test), '\\tmax: ', np.max(X_test))\n",
    "\n",
    "#Output\n",
    "y_test=testing_data[:,-1].reshape(944,1)\n",
    "\n",
    "a_j1 = np.dot(X_test, weight[0]) # a_j1 is 944 by 4 vector: linear comb output in hidden layer based on X\n",
    "z_j1 = sigmoid(a_j1) # z_j1 is 944 by 4 vector: sigmoid transformation output in hidden layer based on X\n",
    "a_k1 = np.dot(z_j1, weight[1]) # a_k1 is 944 by 1 value in output layer\n",
    "z_k1 = sigmoid(a_k1)\n",
    "\n",
    "prediction_testing = np.zeros((944,1))\n",
    "for i in range(944):\n",
    "    if z_k1[[i]] >= 0.0050:\n",
    "        prediction_testing[[i]] = 1\n",
    "    else:\n",
    "        prediction_testing[[i]] = 0\n",
    "print(\"Testing Accuracy is\",(np.sum(prediction_testing == y_test))/ len(prediction_testing))\n",
    "print(\"Testing Error is\", 1 - ((np.sum(prediction_testing == y_test))/ len(prediction_testing)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
